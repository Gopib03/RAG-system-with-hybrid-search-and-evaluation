import sys
sys.path.append('src')

from retrieval.hybrid import HybridSearch
from generation.generator import AnswerGenerator
from evaluation.metrics import RAGEvaluator

print("ðŸ§ª Quick System Test\n")

# Load search
print("ðŸ“‚ Loading search index...")
hybrid = HybridSearch()
hybrid.load('data/embeddings/hybrid_index')

# Create components
print("ðŸ¤– Initializing generator...")
generator = AnswerGenerator()

print("ðŸ“Š Initializing evaluator...")
evaluator = RAGEvaluator()

# Test questions
questions = [
    "What is machine learning?",
    "How do neural networks work?",
    "What is deep learning?"
]

print("\n" + "="*60)
for i, question in enumerate(questions, 1):
    print(f"\n[{i}/{len(questions)}] {question}")
    print("-"*60)
    
    # Retrieve
    chunks = hybrid.search(question, k=5)
    print(f"âœ… Retrieved {len(chunks)} chunks")
    
    # Generate
    result = generator.generate(question, chunks)
    print(f"\nðŸ’¬ Answer:\n{result['answer'][:200]}...")
    print(f"\nðŸ”¢ Tokens: {result['tokens_used']}")
    
    # Evaluate
    context = [c['content'] for c, _ in chunks]
    metrics = evaluator.evaluate_response(question, result['answer'], context)
    
    print(f"\nðŸ“Š Metrics:")
    print(f"  Relevancy: {metrics['answer_relevancy']:.1f}/5")
    print(f"  Faithfulness: {metrics['faithfulness']:.0%}")
    print(f"  Overall: {metrics['overall_score']:.0%}")

print("\n" + "="*60)
print("âœ… System test complete!")