import sys
sys.path.append('src')

from dotenv import load_dotenv
load_dotenv()  # This loads the .env file
import os

from retrieval.hybrid import HybridSearch
from generation.generator import AnswerGenerator

print("\n" + "="*70)
print("ğŸ§ª COMPLETE SYSTEM TEST")
print("="*70)

# Load search
print("\nğŸ“‚ Loading search index...")
hybrid = HybridSearch()
hybrid.load('data/embeddings/hybrid_index')

# Create generator
print("ğŸ¤– Initializing answer generator...")
generator = AnswerGenerator()

# Test questions
questions = [
    "What is machine learning?",
    "How do neural networks work?",
    "What are the main types of machine learning?"
]

print("\n" + "="*70)
print("RUNNING QUERIES")
print("="*70)

for i, question in enumerate(questions, 1):
    print(f"\n[{i}/{len(questions)}] â“ {question}")
    print("-"*70)
    
    # Retrieve
    chunks = hybrid.search(question, k=5)
    print(f"âœ… Retrieved {len(chunks)} relevant chunks")
    
    # Generate
    result = generator.generate(question, chunks)
    
    print(f"\nğŸ’¬ ANSWER:")
    print(result['answer'])
    
    print(f"\nğŸ“Š STATS:")
    print(f"   â€¢ Tokens used: {result['tokens_used']}")
    print(f"   â€¢ Sources: {len(result['sources'])}")
    print(f"   â€¢ Model: {result['model']}")

print("\n" + "="*70)
print("âœ… COMPLETE SYSTEM TEST PASSED!")
print("="*70)
print("\nğŸ‰ Your RAG system is fully operational!")
print("\nğŸ“ What you've built:")
print("   â€¢ Hybrid search (vector + keyword)")
print("   â€¢ 7,712 chunks indexed")
print("   â€¢ Claude Haiku for answers")
print("   â€¢ Complete RAG pipeline")
print("\nğŸ’¼ Ready for your resume!")
print()